{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PRÁCTICA FINAL - PREDICCIÓN DE DURACIÓN DE VIAJES Y DETECCIÓN DE EMERGENCIAS EN TWEETS**\n",
    "\n",
    "**Asignatura:** Modelos no supervisados\n",
    "\n",
    "**Fecha:** 09/06/2023\n",
    "\n",
    "**Autores:** Mencía de Parias y Juan María Rotaeche"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 0: Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random_state = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 1: Predicción de duración de viajes**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 1**\n",
    "\n",
    "Realizar preprocesamiento de datos: imputar valores faltantes, transformar variables categóricas, estandarizar variables numéricas, etc. \n",
    "si lo consideras necesario para futuros modelos. Puede ser interesante intentar adaptar las variables que no siguan una distribución normal mediante técnicas de mapeado a gausianas como Power Transformers (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer). *(2puntos)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar leemos ambos DataFrames y con *head ()* nos hacemos una idea de la forma que tienen. Utilizamos también *shape* para ver la dimensionalidad de ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_examples = pd.read_csv('uber_time_examples.csv')\n",
    "uber_labels = pd.read_csv('uber_time_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 12) (400000, 2)\n",
      "   id       feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0  01-07 17:04:08          2       1.20        263        141  12.513054   \n",
      "1   1  03-02 17:41:40          1       0.88        246         68   6.256527   \n",
      "2   2  02-17 12:15:00          3       7.61         24         13  18.769581   \n",
      "3   3  03-30 13:59:42          1       1.50        239        163   6.256527   \n",
      "4   4  02-14 18:26:55          1       1.20        142        229   6.256527   \n",
      "\n",
      "    feature_6  feature_7  feature_8  feature_9  feature_10  \n",
      "0  297.430685  56.317405     405.20   0.408689  126.689773  \n",
      "1  278.205127  27.160167     314.88  -0.256911  126.693467  \n",
      "2   27.141964   5.192385      44.61  56.880789  126.615789  \n",
      "3  270.288721  65.104518     403.50   1.218689  126.686311  \n",
      "4  160.589952  91.465857     372.20   0.408689  126.689773      id  duration\n",
      "0   0     455.0\n",
      "1   1     413.0\n",
      "2   2    1501.0\n",
      "3   3     514.0\n",
      "4   4     605.0\n"
     ]
    }
   ],
   "source": [
    "print (uber_examples.shape, \n",
    "       uber_labels.shape)\n",
    "print (uber_examples.head(), \n",
    "       uber_labels.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas tablas tienen el mismo número de filas y la columna *id* para identificar los registros, por lo que el primer paso es unir los datos en base a esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>01-07 17:04:08</td>\n",
       "      <td>2</td>\n",
       "      <td>1.20</td>\n",
       "      <td>263</td>\n",
       "      <td>141</td>\n",
       "      <td>12.513054</td>\n",
       "      <td>297.430685</td>\n",
       "      <td>56.317405</td>\n",
       "      <td>405.20</td>\n",
       "      <td>0.408689</td>\n",
       "      <td>126.689773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>413.0</td>\n",
       "      <td>03-02 17:41:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>246</td>\n",
       "      <td>68</td>\n",
       "      <td>6.256527</td>\n",
       "      <td>278.205127</td>\n",
       "      <td>27.160167</td>\n",
       "      <td>314.88</td>\n",
       "      <td>-0.256911</td>\n",
       "      <td>126.693467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>02-17 12:15:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7.61</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>18.769581</td>\n",
       "      <td>27.141964</td>\n",
       "      <td>5.192385</td>\n",
       "      <td>44.61</td>\n",
       "      <td>56.880789</td>\n",
       "      <td>126.615789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>514.0</td>\n",
       "      <td>03-30 13:59:42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>239</td>\n",
       "      <td>163</td>\n",
       "      <td>6.256527</td>\n",
       "      <td>270.288721</td>\n",
       "      <td>65.104518</td>\n",
       "      <td>403.50</td>\n",
       "      <td>1.218689</td>\n",
       "      <td>126.686311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>605.0</td>\n",
       "      <td>02-14 18:26:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>142</td>\n",
       "      <td>229</td>\n",
       "      <td>6.256527</td>\n",
       "      <td>160.589952</td>\n",
       "      <td>91.465857</td>\n",
       "      <td>372.20</td>\n",
       "      <td>0.408689</td>\n",
       "      <td>126.689773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  duration       feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0   0     455.0  01-07 17:04:08          2       1.20        263        141   \n",
       "1   1     413.0  03-02 17:41:40          1       0.88        246         68   \n",
       "2   2    1501.0  02-17 12:15:00          3       7.61         24         13   \n",
       "3   3     514.0  03-30 13:59:42          1       1.50        239        163   \n",
       "4   4     605.0  02-14 18:26:55          1       1.20        142        229   \n",
       "\n",
       "   feature_5   feature_6  feature_7  feature_8  feature_9  feature_10  \n",
       "0  12.513054  297.430685  56.317405     405.20   0.408689  126.689773  \n",
       "1   6.256527  278.205127  27.160167     314.88  -0.256911  126.693467  \n",
       "2  18.769581   27.141964   5.192385      44.61  56.880789  126.615789  \n",
       "3   6.256527  270.288721  65.104518     403.50   1.218689  126.686311  \n",
       "4   6.256527  160.589952  91.465857     372.20   0.408689  126.689773  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber = pd.merge (uber_labels, uber_examples, on = 'id')\n",
    "uber.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos listos para empezar a trabajar, primero vamos a realizar un preprocesamiento de datos. Para ello, primero trabajaremos con los valores nulos si los hubiera; después analizaremos el tipo de variables que tenemos y si es necesario transformar alguna; y si realizamos una transformación a las variables que no siguen una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "duration      0\n",
       "feature_0     0\n",
       "feature_1     0\n",
       "feature_2     0\n",
       "feature_3     0\n",
       "feature_4     0\n",
       "feature_5     0\n",
       "feature_6     0\n",
       "feature_7     0\n",
       "feature_8     0\n",
       "feature_9     0\n",
       "feature_10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todo nuestro conjunto de datos no hay ningún valor faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              int64\n",
       "duration      float64\n",
       "feature_0      object\n",
       "feature_1       int64\n",
       "feature_2     float64\n",
       "feature_3       int64\n",
       "feature_4       int64\n",
       "feature_5     float64\n",
       "feature_6     float64\n",
       "feature_7     float64\n",
       "feature_8     float64\n",
       "feature_9     float64\n",
       "feature_10    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber['feature_0'] = pd.to_datetime(uber['feature_0'], format='%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador= PowerTransformer(method='yeo-johnson')\n",
    "uber['duration'] = transformador.fit_transform(uber[['duration']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única columna a la que conviene cambiarle el tipo de datos es a *feature_0* ya que muestra una fecha pero está en formato object.\n",
    "\n",
    "Además, con el método Yeo-Johnson de PowerTransformer hemos normlaizado la variable objetivo: *duration*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 2**\n",
    "\n",
    "Crear nuevas características (features) que puedan mejorar el poder predictivo del modelo. *(1 punto)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una columna en formato tiempo, y puede ser interesante crear tres diferentes en base a esta para tener el dia, mes y hora de cada reserva de hora. Así podremos ver la evolución a lo largo de los meses o si en algún dia/a alguna hora los trayectos son más largos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber['day'] = uber['feature_0'].dt.day\n",
    "uber['month'] = uber['feature_0'].dt.month\n",
    "uber['hour'] = uber['feature_0'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = uber.drop(['feature_0'], axis=1) #elimino la columna de las fechas xq creo que ya no aporta info\n",
    "uber = uber.drop(['id'], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creadas estas tres nuevas columnas, la columna *feature_0* en formato fecha no nos aporta mucha más información. Además, tenemos una columna: *id* que tampoco nos aporta información. Para mejorar la capacidad predictora del modelo vamos a eliminar ambas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration       5592\n",
       "feature_1        10\n",
       "feature_2      2709\n",
       "feature_3       231\n",
       "feature_4       255\n",
       "feature_5        10\n",
       "feature_6       231\n",
       "feature_7       255\n",
       "feature_8     40197\n",
       "feature_9      2709\n",
       "feature_10     2709\n",
       "day              31\n",
       "month             4\n",
       "hour             24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = pd.get_dummies(uber, columns = ['month'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con *nunique()* obtenemos el número de valores únicos que toma cada variable. En este caso, hemos hecho un *get_dummies* de month que solo toma 4 valores diferentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 3**\n",
    "\n",
    "Seleccionar las características más relevantes para predecir la duración del viaje. Utilizar técnicas de selección de características basadas en una sola variable o SelectFromModel. Evitar Recursive feature elimination debido a su alto coste computacional.\n",
    "Ver : (https://scikit-learn.org/stable/modules/feature_selection.html) *(2puntos)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como técnica de selección de caracterísitcas más importantes en relación a la variable objetivo hemos utilizado la correlación. Además hemos comprobado después con *SelectFromModel* para ver si nos daban los mismos resultados ya que una variable puede estar muy correlacionada con la objetivo de forma negativa y no daría como resultado que están altamente relacionadas cuando si que lo están."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration      1.000000\n",
       "feature_2     0.551888\n",
       "feature_10    0.551888\n",
       "feature_7     0.080211\n",
       "feature_4     0.080211\n",
       "feature_8     0.071753\n",
       "feature_6     0.058250\n",
       "feature_3     0.058250\n",
       "hour          0.040001\n",
       "feature_1     0.018312\n",
       "feature_5     0.018312\n",
       "feature_9     0.016372\n",
       "day           0.014297\n",
       "month_3       0.012911\n",
       "month_1       0.011181\n",
       "month_12      0.007903\n",
       "month_2       0.002041\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMO TECNICA DE SELECCION DE CARACTERÍSTICAS BASADA EN UNA VARIABLE USAMOS CORRELACIÓN, FALTA DEFINIR THRESHOLD EN LA ULTIMA LINEA DE CODIGO\n",
    "correlation_matrix = uber.corr()\n",
    "correlation_with_target = correlation_matrix['duration'].abs().sort_values(ascending=False)\n",
    "correlation_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_10: 0.3653198412808319\n",
      "feature_2: 0.1679752337924987\n",
      "feature_9: 0.16287291163222803\n",
      "feature_8: 0.06408406411244687\n",
      "hour: 0.05704190970428596\n",
      "day: 0.05166053683278204\n",
      "feature_4: 0.024535798216441668\n",
      "feature_7: 0.0243346619432212\n",
      "feature_6: 0.022176420273611844\n",
      "feature_3: 0.022140207636935107\n",
      "feature_1: 0.008739662181853514\n",
      "feature_5: 0.008647341081112344\n",
      "month_1: 0.007176558429115445\n",
      "month_3: 0.006656301324834602\n",
      "month_2: 0.006458697315644591\n",
      "month_12: 0.00017985424215624595\n"
     ]
    }
   ],
   "source": [
    "# Separar las características y la variable objetivo\n",
    "X = uber.drop(['duration'], axis=1)\n",
    "y = uber['duration']\n",
    "\n",
    "# Crear un modelo clasificador basado en árboles\n",
    "modelo = RandomForestRegressor()\n",
    "modelo.fit(X, y)\n",
    "\n",
    "importancias = modelo.feature_importances_\n",
    "\n",
    "# Crear un diccionario de características y sus importancias\n",
    "diccionario_importancias = dict(zip(X.columns, importancias))\n",
    "\n",
    "# Imprimir las importancias de las características en orden descendente\n",
    "for caracteristica, importancia in sorted(diccionario_importancias.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{caracteristica}: {importancia}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado que tenemos es ligeramente diferente, así que nos quedamos con el de *SelecFromModel* para concluir que las características más importantes en relación a la variable objetivo son: *feature_10*, *feature_2* y *feature_9*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 4**\n",
    "\n",
    "Entrenar un modelo sencillo como base y medir su MAPE (Mean Absolute Percentage Error) en el conjunto de test. Luego, elegir y entrenar dos modelos más avanzados (por ejemplo, ensambladores, máquinas de soporte vectorial, modelos bayesianos, redes neuronales) y comparar sus MAPEs. *(2puntos)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio trabajaremos con una muestra de 20,000 filas del conjunto original de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_sample = uber.sample(n=20000, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = uber_sample.drop(['duration'], axis=1)\n",
    "y = uber_sample['duration']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, dividimos nuestro conjunto de datos en dos dataframes, uno que contiene todas las variables excepto la objetivo y otro solo con la variable objetivo. Dividimos ambos en conjuntos de test y entrenamiento.\n",
    "\n",
    "No normalizamos, hemos probado y da mejores resultados sin normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Duración Real  Duración Predicha  Squared Error\n",
      "0             261.0         375.718319   1.316029e+04\n",
      "1            1675.0        3317.384853   2.697428e+06\n",
      "2             263.0         408.196204   2.108194e+04\n",
      "3             515.0         486.138736   8.329726e+02\n",
      "4             630.0         426.524474   4.140229e+04\n",
      "...             ...                ...            ...\n",
      "5995          233.0         404.139586   2.928876e+04\n",
      "5996          283.0         363.237076   6.437988e+03\n",
      "5997         1002.0         692.664550   9.568842e+04\n",
      "5998          558.0         458.887796   9.823229e+03\n",
      "5999          678.0         428.482465   6.225900e+04\n",
      "\n",
      "[6000 rows x 3 columns]\n",
      "MAPE del modelo base: 0.9993614372456142\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo de regresión lineal\n",
    "modelo_base = LinearRegression()\n",
    "modelo_base.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predicciones_base = modelo_base.predict(X_test)\n",
    "\n",
    "y_pred_inv = transformador.inverse_transform(predicciones_base.reshape(-1, 1))\n",
    "y_test_inv = transformador.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Calcular el error al cuadrado\n",
    "squared_error = (y_pred_inv - y_test_inv) ** 2\n",
    "\n",
    "resultados = pd.DataFrame({'Duración Real': y_test_inv.flatten(),\n",
    "                            'Duración Predicha': y_pred_inv.flatten(),\n",
    "                            'Squared Error': squared_error.flatten()})\n",
    "\n",
    "print(resultados)\n",
    "\n",
    "mse_lr = mean_squared_error(resultados['Duración Real'], resultados['Duración Predicha'], squared=False)\n",
    "\n",
    "# Calcular el MAPE utilizando las predicciones inversas\n",
    "mape_lr = mean_absolute_percentage_error(transformador.inverse_transform(y_test_inv), y_pred_inv)\n",
    "print(f\"MAPE del modelo base: {mape_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Duración Real  Duración Predicha  Squared Error\n",
      "0             261.0         230.616687     923.145725\n",
      "1            1675.0        1783.396555   11749.813096\n",
      "2             263.0         221.324508    1736.846649\n",
      "3             515.0         500.685772     204.897115\n",
      "4             630.0         500.989185   16643.790458\n",
      "...             ...                ...            ...\n",
      "5995          233.0         275.887453    1839.333622\n",
      "5996          283.0         225.979009    3251.393416\n",
      "5997         1002.0         921.832267    6426.865421\n",
      "5998          558.0         382.673984   30739.211972\n",
      "5999          678.0         597.240184    6522.147873\n",
      "\n",
      "[6000 rows x 3 columns]\n",
      "MAPE del modelo Random Forest: 0.9997873962386802\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo de Random Forest (ensambladores)\n",
    "modelo_rf = RandomForestRegressor()\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predicciones_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "y_pred_rf_inv = transformador.inverse_transform(predicciones_rf.reshape(-1, 1))\n",
    "y_test_rf_inv = transformador.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Calcular el error al cuadrado\n",
    "squared_error_rf = (y_pred_rf_inv - y_test_rf_inv) ** 2\n",
    "\n",
    "resultados_rf = pd.DataFrame({'Duración Real': y_test_rf_inv.flatten(),\n",
    "                            'Duración Predicha': y_pred_rf_inv.flatten(),\n",
    "                            'Squared Error': squared_error_rf.flatten()})\n",
    "\n",
    "print(resultados_rf)\n",
    "\n",
    "mse_rf = mean_squared_error(resultados_rf['Duración Real'], resultados_rf['Duración Predicha'], squared=False)\n",
    "\n",
    "# Calcular el MAPE en el conjunto de prueba para Random Forest\n",
    "mape_rf = mean_absolute_percentage_error(transformador.inverse_transform(y_test_rf_inv), y_pred_rf_inv)\n",
    "print(f\"MAPE del modelo Random Forest: {mape_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Duración Real  Duración Predicha  Squared Error\n",
      "0             261.0         620.718925   1.293977e+05\n",
      "1            1675.0         627.489652   1.097278e+06\n",
      "2             263.0         504.047493   5.810389e+04\n",
      "3             515.0         577.540711   3.911341e+03\n",
      "4             630.0         627.489651   6.301851e+00\n",
      "...             ...                ...            ...\n",
      "5995          233.0         280.449850   2.251488e+03\n",
      "5996          283.0         627.384461   1.186007e+05\n",
      "5997         1002.0         627.489652   1.402580e+05\n",
      "5998          558.0         615.855838   3.347298e+03\n",
      "5999          678.0         627.487695   2.551493e+03\n",
      "\n",
      "[6000 rows x 3 columns]\n",
      "MAPE del modelo Random Forest: 0.9988707254904025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Crear un modelo de Máquinas de Soporte Vectorial (SVM)\n",
    "modelo_svm = SVR(kernel='rbf', C=100, gamma=0.2, epsilon=1.1, max_iter=50000)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predicciones_svm = modelo_svm.predict(X_test)\n",
    "y_pred_svm_inv = transformador.inverse_transform(predicciones_svm.reshape(-1, 1))\n",
    "y_test_svm_inv = transformador.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Calcular el error al cuadrado\n",
    "squared_error_svm = (y_pred_svm_inv - y_test_svm_inv) ** 2\n",
    "\n",
    "resultados_svm = pd.DataFrame({'Duración Real': y_test_svm_inv.flatten(),\n",
    "                            'Duración Predicha': y_pred_svm_inv.flatten(),\n",
    "                            'Squared Error': squared_error_svm.flatten()})\n",
    "\n",
    "print(resultados_svm)\n",
    "\n",
    "mse_svm = mean_squared_error(resultados_svm['Duración Real'], resultados_svm['Duración Predicha'], squared=False)\n",
    "\n",
    "# Calcular el MAPE en el conjunto de prueba \n",
    "mape_svm = mean_absolute_percentage_error(transformador.inverse_transform(y_test_svm_inv), y_pred_svm_inv)\n",
    "print(f\"MAPE del modelo Random Forest: {mape_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Duración Real  Duración Predicha  Squared Error\n",
      "0             261.0         352.694903   8.407955e+03\n",
      "1            1675.0        4726.247361   9.310110e+06\n",
      "2             263.0         369.431223   1.132761e+04\n",
      "3             515.0         515.777477   6.044710e-01\n",
      "4             630.0         395.166887   5.514659e+04\n",
      "...             ...                ...            ...\n",
      "5995          233.0         347.262867   1.305600e+04\n",
      "5996          283.0         335.038170   2.707971e+03\n",
      "5997         1002.0         918.455123   6.979746e+03\n",
      "5998          558.0         404.020523   2.370968e+04\n",
      "5999          678.0         504.174380   3.021535e+04\n",
      "\n",
      "[6000 rows x 3 columns]\n",
      "MAPE del modelo mlp: 0.9995186742767636\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo MLP (red neuronal)\n",
    "modelo_mlp = MLPRegressor()\n",
    "modelo_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predicciones_mlp = modelo_mlp.predict(X_test)\n",
    "y_pred_mlp_inv = transformador.inverse_transform(predicciones_mlp.reshape(-1, 1))\n",
    "y_test_mlp_inv = transformador.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Calcular el error al cuadrado\n",
    "squared_error_mlp = (y_pred_mlp_inv - y_test_mlp_inv) ** 2\n",
    "\n",
    "resultados_mlp = pd.DataFrame({'Duración Real': y_test_mlp_inv.flatten(),\n",
    "                            'Duración Predicha': y_pred_mlp_inv.flatten(),\n",
    "                            'Squared Error': squared_error_mlp.flatten()})\n",
    "\n",
    "print(resultados_mlp)\n",
    "\n",
    "mse_mlp = mean_squared_error(resultados_mlp['Duración Real'], resultados_mlp['Duración Predicha'], squared=False)\n",
    "\n",
    "# Calcular el MAPE en el conjunto de prueba \n",
    "mape_mlp = mean_absolute_percentage_error(transformador.inverse_transform(y_test_mlp_inv), y_pred_mlp_inv)\n",
    "print(f\"MAPE del modelo mlp: {mape_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4084.617801</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4084.352208</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4131.251089</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>4700.546231</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model          MSE    MAPE\n",
       "0  Linear Regression  4084.617801  0.9994\n",
       "1      Random Forest  4084.352208  0.9998\n",
       "2                SVM  4131.251089  0.9989\n",
       "3                MLP  4700.546231  0.9995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Linear Regression', 'Random Forest', 'SVM', 'MLP']\n",
    "mse = [mse_lr, mse_rf, mse_svm, mse_mlp]\n",
    "mapes = [mape_lr.round(4), mape_rf.round(4), mape_svm.round(4), mape_mlp.round(4)]\n",
    "summary_df = pd.DataFrame({'Model':models, 'MSE':mse, 'MAPE':mapes})\n",
    "summary_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna *MSE* muestra el error cuadrático medio obtenido por cada modelo. El error cuadrático medio es una métrica comúnmente utilizada para evaluar la precisión de los modelos de regresión. Cuanto menor sea el valor del MSE, mejor será el ajuste del modelo a los datos, en este caso el modelo que da mejor resultados en base al MSE es Random Forest.\n",
    "\n",
    "La columna *MAPE* muestra el error porcentual absoluto medio obtenido por cada modelo. El error porcentual absoluto medio es otra métrica de evaluación común para los modelos de regresión. Cuanto menor sea el valor del MAPE, mejor será el ajuste del modelo a los datos. Teniendo en cuenta esta métrica el modelo más acertado es SVM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 5**\n",
    "\n",
    "Optimizar los hiperparámetros de los dos últimos modelos utilizando validación cruzada (cross-validation) y comparar sus MAPEs. Elegir el mejor modelo basándose en estos resultados. *(2puntos)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Modelo Predictor       MSE      MAPE\n",
      "0  Regresión Lineal  0.000000  0.000000\n",
      "1     Random Forest  0.000000  0.000100\n",
      "2               SVM  0.000114  0.040016\n",
      "3               MLP  0.000100  0.009800\n"
     ]
    }
   ],
   "source": [
    "# Crear los DataFrames X y y a partir del df 'uber_sample'\n",
    "X = uber_sample[['duration']]\n",
    "y = uber_sample['duration']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos de las variables predictoras\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Regresión lineal\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Soporte Vectorial (SVM)\n",
    "svm_model = SVR()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# MLP (red neuronal)\n",
    "mlp_model = MLPRegressor()\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Definir los hiperparámetros a explorar para cada modelo\n",
    "linear_params = {}\n",
    "random_forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}\n",
    "svm_params = {'C': [1, 10, 100], 'gamma': [0.1, 0.01, 0.001]}\n",
    "mlp_params = {'hidden_layer_sizes': [(10,), (50,), (100,)], 'activation': ['relu', 'tanh'], 'alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros con validación cruzada (GridSearchCV)\n",
    "linear_model_cv = GridSearchCV(linear_model, linear_params, cv=5)\n",
    "linear_model_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "random_forest_cv = GridSearchCV(random_forest, random_forest_params, cv=5)\n",
    "random_forest_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_model_cv = GridSearchCV(svm_model, svm_params, cv=5)\n",
    "svm_model_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "mlp_model_cv = GridSearchCV(mlp_model, mlp_params, cv=5)\n",
    "mlp_model_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtener los mejores modelos con los hiperparámetros optimizados\n",
    "best_linear_model = linear_model_cv.best_estimator_\n",
    "best_random_forest = random_forest_cv.best_estimator_\n",
    "best_svm_model = svm_model_cv.best_estimator_\n",
    "best_mlp_model = mlp_model_cv.best_estimator_\n",
    "\n",
    "# Realizar las predicciones con los modelos optimizados\n",
    "linear_predictions = best_linear_model.predict(X_test_scaled)\n",
    "random_forest_predictions = best_random_forest.predict(X_test_scaled)\n",
    "svm_predictions = best_svm_model.predict(X_test_scaled)\n",
    "mlp_predictions = best_mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular los MSE y MAPE para cada modelo\n",
    "linear_mse = mean_squared_error(y_test, linear_predictions)\n",
    "linear_mape = mean_absolute_percentage_error(y_test, linear_predictions)\n",
    "\n",
    "random_forest_mse = mean_squared_error(y_test, random_forest_predictions)\n",
    "random_forest_mape = mean_absolute_percentage_error(y_test, random_forest_predictions)\n",
    "\n",
    "svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "svm_mape = mean_absolute_percentage_error(y_test, svm_predictions)\n",
    "\n",
    "mlp_mse = mean_squared_error(y_test, mlp_predictions)\n",
    "mlp_mape = mean_absolute_percentage_error(y_test, mlp_predictions)\n",
    "\n",
    "# Crear el DataFrame con los resultados\n",
    "results = pd.DataFrame({\n",
    "    'Modelo Predictor': ['Regresión Lineal', 'Random Forest', 'SVM', 'MLP'],\n",
    "    'MSE': [linear_mse.round(4), random_forest_mse.round(4), svm_mse, mlp_mse.round(4)],\n",
    "    'MAPE': [linear_mape.round(4), random_forest_mape.round(4), svm_mape, mlp_mape.round(4)]\n",
    "})\n",
    "\n",
    "# Mostrar el DataFrame con los resultados\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 2: Detección de emergencias en tweets**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 1:**\n",
    "\n",
    "Extraer los embeddings del texto de los tweets utilizando un modelo pre-entrenado de Huggingface. *(1.5 puntos)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, leemos la tabla *twitter* y imputamos *desconocido* en todos los valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = pd.read_csv('twitter_emergency.csv')\n",
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64 (7613, 5)\n"
     ]
    }
   ],
   "source": [
    "print (twitter.isnull().sum(),\n",
    "twitter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter.fillna('desconocido')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el modelo *roberta-base* de HuggingFace para obtener los embeddigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo y el tokenizer pre-entrenados\n",
    "modelo = AutoModel.from_pretrained('roberta-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Obtener los textos de los tweets\n",
    "tweets = twitter['text'].tolist()\n",
    "\n",
    "# Tokenizar los textos de los tweets\n",
    "tokens = tokenizer(tweets, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Obtener los embeddings de los tweets\n",
    "with torch.no_grad():\n",
    "    outputs = modelo(**tokens)\n",
    "\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Los embeddings ahora contienen los vectores de representación del texto de los tweets\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ejercicio 2:**\n",
    "\n",
    "Crear y entrenar una pequeña red neuronal que utilice los embeddings, la palabra clave (keyword) y la ubicación (location) para predecir si un tweet está relacionado con una emergencia o no. Gestionar los valores faltantes y agrupar las variables categóricas de manera adecuada. No es necesario realizar una optimización de hiperparámetros exhaustiva, pero se pueden realizar ajustes si se desea. \n",
    "\n",
    "NOTA: Si no se ha podido calcular los embeddings del ejercicio anterior, usar los que aparecen guardados como numpy.array en el fichero. *(1.5 puntos)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_pickle(r\"C:\\Users\\menci\\OneDrive - Colegio Universitario de Estudios Financieros (CUNEF)\\CUNEF\\4. CUARTO\\2CUATRIMESTRE (NEWCASTLE)\\Modelos supervisados\\Practica-final\\Practica-final\\tweet_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 2s 2ms/step - loss: 0.4925 - accuracy: 0.7827\n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8511\n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8820\n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9023\n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9243\n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9288\n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9420\n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9533\n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.9640\n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9617\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.7856\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.7914\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8553\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8852\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2337 - accuracy: 0.9054\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9355\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1455 - accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9516\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1125 - accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9606\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.7414 - accuracy: 0.8052\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.7943\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8601\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.8829\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2253 - accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9203\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9358\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1431 - accuracy: 0.9423\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9468\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9527\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1038 - accuracy: 0.9598\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.8081 - accuracy: 0.7900\n",
      "Epoch 1/10\n",
      "222/222 [==============================] - 2s 3ms/step - loss: 0.4806 - accuracy: 0.7894\n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.8823\n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9060\n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9248\n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1726 - accuracy: 0.9352\n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9479\n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1133 - accuracy: 0.9597\n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9623\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.8763 - accuracy: 0.8115\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 2s 3ms/step - loss: 0.4850 - accuracy: 0.7850\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8860\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9305\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1558 - accuracy: 0.9429\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1288 - accuracy: 0.9522\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1212 - accuracy: 0.9558\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9628\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.9371 - accuracy: 0.8131\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.7990\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8610\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8902\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2315 - accuracy: 0.9099\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9209\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1555 - accuracy: 0.9381\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9485\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1259 - accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1175 - accuracy: 0.9575\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9589\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.8007\n",
      "Epoch 1/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.7790\n",
      "Epoch 2/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8570\n",
      "Epoch 3/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8834\n",
      "Epoch 4/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9037\n",
      "Epoch 5/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9198\n",
      "Epoch 6/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9338\n",
      "Epoch 7/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9423\n",
      "Epoch 8/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9550\n",
      "Epoch 9/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9527\n",
      "Epoch 10/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9620\n",
      "Epoch 11/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9640\n",
      "Epoch 12/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9659\n",
      "Epoch 13/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9614\n",
      "Epoch 14/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9657\n",
      "Epoch 15/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9713\n",
      "Epoch 16/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9733\n",
      "Epoch 17/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9668\n",
      "Epoch 18/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9721\n",
      "Epoch 19/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9727\n",
      "Epoch 20/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9735\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.7873\n",
      "Epoch 1/20\n",
      "223/223 [==============================] - 2s 3ms/step - loss: 0.4734 - accuracy: 0.7872\n",
      "Epoch 2/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8570\n",
      "Epoch 3/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8801\n",
      "Epoch 4/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2201 - accuracy: 0.9094\n",
      "Epoch 5/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.9274\n",
      "Epoch 6/20\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9386\n",
      "Epoch 7/20\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9468\n",
      "Epoch 8/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1178 - accuracy: 0.9555\n",
      "Epoch 9/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1205 - accuracy: 0.9561\n",
      "Epoch 10/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9628\n",
      "Epoch 11/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9634\n",
      "Epoch 12/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9651\n",
      "Epoch 13/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9693\n",
      "Epoch 14/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9730\n",
      "Epoch 15/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9713\n",
      "Epoch 16/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9730\n",
      "Epoch 17/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9727\n",
      "Epoch 20/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9766\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.7962\n",
      "Epoch 1/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7889\n",
      "Epoch 2/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.8638\n",
      "Epoch 3/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2785 - accuracy: 0.8905\n",
      "Epoch 4/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.8973\n",
      "Epoch 5/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9173\n",
      "Epoch 6/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1845 - accuracy: 0.9299\n",
      "Epoch 7/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9378\n",
      "Epoch 8/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9527\n",
      "Epoch 9/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9499\n",
      "Epoch 10/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9612\n",
      "Epoch 11/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9631\n",
      "Epoch 13/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9626\n",
      "Epoch 14/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9679\n",
      "Epoch 15/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9657\n",
      "Epoch 16/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9648\n",
      "Epoch 17/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9690\n",
      "Epoch 18/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9688\n",
      "Epoch 19/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9690\n",
      "Epoch 20/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9710\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.9371 - accuracy: 0.7973\n",
      "Epoch 1/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.4792 - accuracy: 0.7911\n",
      "Epoch 2/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8485\n",
      "Epoch 3/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8803\n",
      "Epoch 4/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2463 - accuracy: 0.9046\n",
      "Epoch 5/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1930 - accuracy: 0.9203\n",
      "Epoch 6/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9392\n",
      "Epoch 7/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9505\n",
      "Epoch 8/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.9603\n",
      "Epoch 9/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1202 - accuracy: 0.9524\n",
      "Epoch 10/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9676\n",
      "Epoch 11/20\n",
      "222/222 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9690\n",
      "Epoch 14/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9724\n",
      "Epoch 15/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9718\n",
      "Epoch 16/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9716\n",
      "Epoch 17/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9792\n",
      "Epoch 19/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9786\n",
      "Epoch 20/20\n",
      "222/222 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9764\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 1.3210 - accuracy: 0.8087\n",
      "Epoch 1/20\n",
      "223/223 [==============================] - 2s 3ms/step - loss: 0.4871 - accuracy: 0.7906\n",
      "Epoch 2/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8491\n",
      "Epoch 3/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8888\n",
      "Epoch 4/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2303 - accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9257\n",
      "Epoch 6/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9370\n",
      "Epoch 7/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1336 - accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1129 - accuracy: 0.9586\n",
      "Epoch 10/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9620\n",
      "Epoch 11/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9665\n",
      "Epoch 12/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9730\n",
      "Epoch 14/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9733\n",
      "Epoch 15/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9752\n",
      "Epoch 16/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9735\n",
      "Epoch 17/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9769\n",
      "Epoch 18/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0771 - accuracy: 0.9747\n",
      "Epoch 19/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.9792\n",
      "Epoch 20/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9766\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.8018\n",
      "Epoch 1/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.7993\n",
      "Epoch 2/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8612\n",
      "Epoch 3/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9189\n",
      "Epoch 6/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9364\n",
      "Epoch 7/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1393 - accuracy: 0.9485\n",
      "Epoch 8/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9533\n",
      "Epoch 9/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1224 - accuracy: 0.9595\n",
      "Epoch 10/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9637\n",
      "Epoch 11/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1029 - accuracy: 0.9620\n",
      "Epoch 12/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9631\n",
      "Epoch 13/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9699\n",
      "Epoch 14/20\n",
      "223/223 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9659\n",
      "Epoch 15/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9676\n",
      "Epoch 16/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9654\n",
      "Epoch 17/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9685\n",
      "Epoch 18/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9724\n",
      "Epoch 19/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.9713\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 1.2166 - accuracy: 0.8069\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7796\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8567\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8865\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9009\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9341\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9448\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9533\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9595\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9586\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.8047\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7709\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8748\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9009\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9187\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9308\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9381\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9564\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9493\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.8024\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.7943\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8551\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8846\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9170\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9344\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9403\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9491\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9558\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9598\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.7900\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7863\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8834\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9398\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9471\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9505\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9581\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9634\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.8097 - accuracy: 0.8092\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4788 - accuracy: 0.7816\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8829\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.8998\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9274\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9350\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9567\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9654\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.7744 - accuracy: 0.8063\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4706 - accuracy: 0.7948\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8601\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8854\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9153\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9325\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9465\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9538\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9606\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9643\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.8427 - accuracy: 0.7900\n",
      "Epoch 1/20\n",
      "111/111 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7784\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8463\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8775\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9062\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9192\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9330\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9443\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9541\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9561\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9631\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9673\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9744\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9718\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9716\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9772\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9744\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9758\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9761\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9713\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.7867\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4892 - accuracy: 0.7740\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8525\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8778\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.8981\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2008 - accuracy: 0.9254\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9277\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9386\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9485\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9612\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9637\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9564\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9707\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9659\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9719\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9735\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9710\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9724\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9778\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9755\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9766\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.9629 - accuracy: 0.8007\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.7940\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8559\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8846\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9091\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9164\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9417\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9409\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9552\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9561\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9620\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9637\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9690\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9648\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9668\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9688\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9699\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9704\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9688\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9744\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9750\n",
      "56/56 [==============================] - 1s 2ms/step - loss: 0.9752 - accuracy: 0.8035\n",
      "Epoch 1/20\n",
      "111/111 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7782\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8525\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8970\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9195\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9367\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9462\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9561\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9572\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9609\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9645\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9730\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9730\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9707\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9764\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9710\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9741\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9755\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.0768 - accuracy: 0.8092\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.7841\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8612\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8829\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9035\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9243\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9381\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9527\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9567\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9583\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9665\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9679\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9707\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9727\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9727\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9719\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9755\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9766\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9800\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.1111 - accuracy: 0.7967\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4727 - accuracy: 0.7912\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8610\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8762\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9068\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9203\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9353\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9499\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9564\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9589\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9668\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9738\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9651\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9699\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9738\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9727\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9738\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9733\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.1768 - accuracy: 0.7917\n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 2s 3ms/step - loss: 0.4660 - accuracy: 0.7990\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8491\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8758\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8904\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9075\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9264\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1693 - accuracy: 0.9351\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9422\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9501\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9478\n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 2s 3ms/step - loss: 0.4695 - accuracy: 0.7979\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3594 - accuracy: 0.8474\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8688\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2283 - accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9214\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.9315\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9369\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9514\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "MSE del modelo: 0.16\n",
      "MAE del modelo: 0.21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "encoder = LabelEncoder()\n",
    "twitter['keyword'] = encoder.fit_transform(twitter['keyword'])\n",
    "twitter['location'] = encoder.fit_transform(twitter['location'])\n",
    "\n",
    "# Preparar los datos de entrada y salida\n",
    "X = np.concatenate([embeddings, twitter[['keyword', 'location']].values], axis=1)\n",
    "y = twitter['target'].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear una función para construir el modelo de red neuronal\n",
    "def create_model(optimizer_name):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train_scaled.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    else:\n",
    "        optimizer = 'rmsprop'\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Crear el modelo utilizando KerasClassifier para ser compatible con GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [10, 20],\n",
    "    'optimizer_name': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Crear y entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = create_model(best_params['optimizer_name'])\n",
    "best_model.fit(X_train_scaled, y_train, batch_size=best_params['batch_size'], epochs=best_params['epochs'])\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE del modelo: %.2f\" % mse)\n",
    "\n",
    "# Calcular el error absoluto medio (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE del modelo: %.2f\" % mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 2s 6ms/step - loss: 0.5376 - accuracy: 0.7784 - val_loss: 0.3930 - val_accuracy: 0.8345\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.4180 - accuracy: 0.8259 - val_loss: 0.3882 - val_accuracy: 0.8371\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.3658 - accuracy: 0.8441 - val_loss: 0.3924 - val_accuracy: 0.8398\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8602 - val_loss: 0.3978 - val_accuracy: 0.8415\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8660 - val_loss: 0.4052 - val_accuracy: 0.8411\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.8775 - val_loss: 0.4071 - val_accuracy: 0.8376\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8889 - val_loss: 0.4232 - val_accuracy: 0.8354\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8900 - val_loss: 0.4352 - val_accuracy: 0.8332\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8906 - val_loss: 0.4325 - val_accuracy: 0.8327\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.2431 - accuracy: 0.9020 - val_loss: 0.4483 - val_accuracy: 0.8332\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "MSE del modelo: 0.13\n",
      "MAE del modelo: 0.20\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# Agrupar variables categóricas\n",
    "twitter_encoded = pd.get_dummies(twitter, columns=['keyword', 'location'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, twitter_encoded['target'], test_size=0.3, random_state=random_state)\n",
    "\n",
    "# Escalado de características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo de red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE del modelo: %.2f\" % mse)\n",
    "\n",
    "# Calcular el error absoluto medio (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE del modelo: %.2f\" % mae)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los dos modelos de red neuronal creados para predecir si un tweet está relacionado con una emergencia o no en base a *keyword* y a *location*, funciona mejor el segundo en el que no se realiza optimización de hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
